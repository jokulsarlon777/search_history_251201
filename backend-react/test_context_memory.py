"""
Test context memory in multi-turn conversation
"""
import asyncio
from langgraph_sdk import get_client

async def test_context_memory():
    """Test if agent remembers context from previous turns"""

    client = get_client(url="http://127.0.0.1:2025")
    thread = await client.threads.create()
    print(f"âœ… Created thread: {thread['thread_id']}\n")

    # Turn 1: Initial search
    print("="*60)
    print("[í„´ 1] ì‚¬ìš©ì: ì°¨ëŸ‰ ë¸Œë ˆì´í¬ ë¬¸ì œì  ê²€ìƒ‰í•´ì¤˜")
    print("="*60)

    stream1 = client.runs.stream(
        thread["thread_id"],
        "react_agent",
        input={"messages": [{"role": "user", "content": "ì°¨ëŸ‰ ë¸Œë ˆì´í¬ ë¬¸ì œì  ê²€ìƒ‰í•´ì¤˜"}]},
        stream_mode=["values"]
    )

    turn1_response = ""
    async for chunk in stream1:
        if chunk.event == "values":
            messages = chunk.data.get("messages", [])
            if messages:
                last_msg = messages[-1]
                if hasattr(last_msg, "content") and hasattr(last_msg, "type") and last_msg.type == "ai":
                    turn1_response = last_msg.content

    if turn1_response:
        print(f"\n[AI ë‹µë³€]")
        print(turn1_response[:500] + "...\n" if len(turn1_response) > 500 else turn1_response + "\n")

    await asyncio.sleep(2)

    # Turn 2: Follow-up question that requires context
    print("="*60)
    print("[í„´ 2] ì‚¬ìš©ì: K5ë§Œ ìì„¸íˆ ì•Œë ¤ì¤˜")
    print("="*60)

    stream2 = client.runs.stream(
        thread["thread_id"],
        "react_agent",
        input={"messages": [{"role": "user", "content": "K5ë§Œ ìì„¸íˆ ì•Œë ¤ì¤˜"}]},
        stream_mode=["values"]
    )

    turn2_response = ""
    async for chunk in stream2:
        if chunk.event == "values":
            messages = chunk.data.get("messages", [])
            if messages:
                last_msg = messages[-1]
                if hasattr(last_msg, "content") and hasattr(last_msg, "type") and last_msg.type == "ai":
                    turn2_response = last_msg.content

    if turn2_response:
        print(f"\n[AI ë‹µë³€]")
        print(turn2_response + "\n")

    # Verification
    print("="*60)
    print("ğŸ” ë¬¸ë§¥ ê¸°ì–µ ê²€ì¦")
    print("="*60)

    state = await client.threads.get_state(thread["thread_id"])
    total_messages = len(state["values"]["messages"])

    # Check if agent referenced previous context
    context_keywords = ["ì´ì „", "ì•ì„œ", "ìœ„ì—ì„œ", "K5"]
    has_context_reference = any(keyword in turn2_response for keyword in context_keywords)

    print(f"âœ… ì´ ë©”ì‹œì§€ ìˆ˜: {total_messages}")
    print(f"âœ… ë¬¸ë§¥ ì°¸ì¡° í™•ì¸: {'YES - Agent referenced previous conversation' if has_context_reference else 'NO'}")
    print(f"âœ… K5 ì–¸ê¸‰ í™•ì¸: {'YES' if 'K5' in turn2_response else 'NO'}")

    # Check if agent avoided re-searching (should use previous results)
    avoided_duplicate_search = "ê²€ìƒ‰" not in turn2_response.lower() or "ì´ì „" in turn2_response.lower()
    print(f"âœ… ì¤‘ë³µ ê²€ìƒ‰ ë°©ì§€: {'YES - Used previous results' if avoided_duplicate_search else 'NO'}")

if __name__ == "__main__":
    asyncio.run(test_context_memory())
